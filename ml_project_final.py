# -*- coding: utf-8 -*-
"""ML project final

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eHy6aGexRXdQnJiX2WrMh79lGA4xGtpt
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset = pd.read_csv('corporate_rating.csv')
X_df = dataset.iloc[:, 5:31]
y_df = dataset.iloc[:, 0]
dataset.dataframeName = 'corporate_rating.csv'

"""Displaying the dimensions"""

print("The credit rating dataset has", dataset.shape[0], "records, each with", dataset.shape[1],
    "attributes")

"""The Structure of dataset"""

dataset.info()

"""We have 26 columns of numerical data and 6 descriptive columns (one of which is the label).There are no missing values."""

dataset.head()

"""Analyzing the Credit ratings:

There are 10 criterias for Credit rating, ranging from AAA to D. The triple-A (AAA) is the most secure rating a company can receive. On the other hand, the rating D is the less secure. It means the company will likely default on its creditors.

The number of ratings we have for each criteria in the dataset:
"""

dataset.Rating.value_counts()

"""We observe that the dataset is very unbalanced. We have 671 triple-Bs (BBB) but only 1 D.

Given the lack of Credit Ratings classified as AAA, CC, C and D we eliminate then from the dataset.

Distribution Graphs (histogram/bar graph) of sampled columns:
"""

dataset['Rating'].value_counts().plot(kind='bar',figsize=(8,4), title="Rating(column 0)", color="darkred")

dataset['Rating Agency Name'].value_counts().plot(kind='bar',figsize=(8,4), title="Rating Agency Name(column 3)", color="darkred")

dataset['Sector'].value_counts().plot(kind='bar',figsize=(8,4), title="Sector(column 5)", color="darkred")

"""Plotting the correlation matrix between the independent variables"""

def plotCorrelationMatrix(dataset, graphWidth):
    filename = dataset.dataframeName
    dataset = dataset.dropna('columns') # drop columns with NaN
    dataset = dataset[[col for col in dataset if dataset[col].nunique() > 1]] # keep columns where there are more than 1 unique values
    if dataset.shape[1] < 2:
        print(f'No correlation plots shown: The number of non-NaN or constant columns ({dataset.shape[1]}) is less than 2')
        return
    corr = dataset.corr()
    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')
    corrMat = plt.matshow(corr, fignum = 1)
    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)
    plt.yticks(range(len(corr.columns)), corr.columns)
    plt.gca().xaxis.tick_bottom()
    plt.colorbar(corrMat)
    plt.title(f'Correlation Matrix for {filename}', fontsize=15)
    plt.show()

plotCorrelationMatrix(dataset, 8)

"""Plotting Scatter plots for 10 columns with thier correlation values as labels"""

def plotScatterMatrix(df, plotSize, textSize):
    df = df.select_dtypes(include =[np.number]) # keep only numerical columns
    # Remove rows and columns that would lead to df being singular
    df = df.dropna('columns')
    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values
    columnNames = list(df)
    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots
        columnNames = columnNames[:10]
    df = df[columnNames]
    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')
    corrs = df.corr().values
    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):
        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.6, 0.15), xycoords='axes fraction', ha='center', va='center', size=textSize)
    plt.suptitle('Scatter and Density Plot')
    plt.show()

plotScatterMatrix(dataset, 30, 15)

"""Descriptive Statistics

There are 25 numerical columns in the dataset, all of each are financial indicators from the companies. The function describe() returns information about the distribution of the data such as quantiles, min and max.
"""

dataset.describe()

"""Skewness and Outliers

We observe a lot of skewness in the data with this first exploration. In this case, it means that most variables in the dataset may have presence of outliers. Taking as observation the table above the first column:

currentRatio: This 50% of its variables between 1.071 and 2.166891. The minimum value is -0.932005 however the maximum value is 1725.505005. It means there is a giant outlier that is extremely distant from most points from the data (currentRatio).
The same pattern can be observed in the following columns such as quickRatio, cashRatio, daysOfSalesOutstanding, netProfitMargin and so on.

To observe how this reflect on the distribution of the data below are some plots of variables chosen randomly.
"""

from random import sample
column_list = list(dataset.columns[6:31])
column_list = sample(column_list,4) 
print(column_list)

figure, axes = plt.subplots(nrows=2, ncols=4, figsize=(9,5))

axes[0, 0].hist(dataset[column_list[0]])
axes[0, 1].hist(dataset[column_list[1]])
axes[1, 0].hist(dataset[column_list[2]])
axes[1, 1].hist(dataset[column_list[3]])

axes[0, 2].boxplot(dataset[column_list[0]])
axes[0, 3].boxplot(dataset[column_list[1]])
axes[1, 2].boxplot(dataset[column_list[2]])
axes[1, 3].boxplot(dataset[column_list[3]])

figure.tight_layout()

"""As predicted, the data is comtaminated by outliers. We cannot observe real behaviour of the distribution because some points differ too much from the others. We will use the function .skew from pandas in all columns. It should return between 0 and 1 if a column is normally distributed."""

dataset.skew(axis=0)

"""We observe this is a generalized problem. As we can see almost all columns are extremely skewed. The following code will return the proportion of outliers in each column ."""

for c in dataset.columns[6:31]:

    q1 = dataset[c].quantile(0.25)
    q3 = dataset[c].quantile(0.75)
    iqr = q3 - q1 #Interquartile range
    fence_low  = q3-1.5*iqr
    fence_high = q1+1.5*iqr
    lower_out = len(dataset.loc[(dataset[c] < fence_low)  ,c])
    upper_out = len(dataset.loc[(dataset[c] > fence_high)  ,c])
    outlier_count = upper_out+lower_out
    prop_out = outlier_count/len(dataset)
    print(c, ": "+"{:.2%}".format(prop_out))

"""Most columns have a significant number of outliers. However it is not clear for us if there are a few rows that all outliers or each of the rows may be contributing individually with some outliers. the below code checks by row the distribution of outliers. We will create a new dataframe as dataset_outlier that will be used with this purpose. In this dataframe every cell will become 1 if the corresponding cell is an outlier in dataset and 0 if it is not."""

dataset_outlier = dataset.copy()

for c in dataset_outlier.columns[6:31]:
    
    q1 = dataset_outlier[c].quantile(0.25)
    q3 = dataset_outlier[c].quantile(0.75)
    iqr = q3 - q1 #Interquartile range
    fence_low  = q3-1.5*iqr
    fence_high = q1+1.5*iqr
    #try:
    for i in range(len(dataset_outlier)):
      if dataset.loc[i,c] < fence_low or dataset.loc[i,c] > fence_high: # if Outlier
          dataset_outlier.loc[i,c] = 1
      else: # Not Outlier
         dataset_outlier.loc[i,c] = 0
    # except KeyError:
    #   print('The key "111" does not exist in the index.')

dataset_outlier.head()

dataset_outlier["total"] = dataset_outlier.sum(axis=1)
dataset_outlier.total.hist(bins = 20)

"""Only up to 400 rows don't have any outliers. Most rows have outliers and maybe they will be useful in the further classification tasks. Therefore we see no value in excluding the outliers from the dataset."""

#Dropping the less values categories
dataset.drop(dataset.index[(dataset["Rating"] == "AAA")],axis=0,inplace=True)
dataset.drop(dataset.index[(dataset["Rating"] == "CC")],axis=0,inplace=True)
dataset.drop(dataset.index[(dataset["Rating"] == "C")],axis=0,inplace=True)
dataset.drop(dataset.index[(dataset["Rating"] == "D")],axis=0,inplace=True)

X_df = dataset.iloc[:, 5:31]
y_df = dataset.iloc[:, 0]

#Label encoding Sector column
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
le1 = LabelEncoder()
y = le1.fit_transform(y_df)
X_df.Sector = le.fit_transform(X_df.Sector)

X=X_df.to_numpy()

#Splitting the data into training and testing data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

#choosing the most optimal features
from sklearn.decomposition import PCA
pca = PCA(n_components = 23)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)

#Transforming the data
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""Plotting again after transforming the dataset again"""

figure, axes = plt.subplots(nrows=2, ncols=4, figsize=(9,5))

axes[0, 0].hist(dataset[column_list[0]])
axes[0, 1].hist(dataset[column_list[1]])
axes[1, 0].hist(dataset[column_list[2]])
axes[1, 1].hist(dataset[column_list[3]])

axes[0, 2].boxplot(dataset[column_list[0]])
axes[1, 2].boxplot(dataset[column_list[1]])
axes[0, 3].boxplot(dataset[column_list[2]])
axes[1, 3].boxplot(dataset[column_list[3]])

figure.tight_layout()

df_rating_no_out = dataset.copy()

for c in df_rating_no_out.columns[6:31]:

    q05 = df_rating_no_out[c].quantile(0.10)
    q95 = df_rating_no_out[c].quantile(0.90)
    iqr = q95 - q05 #Interquartile range
    fence_low  = q05-1.5*iqr
    fence_high = q95+1.5*iqr
    df_rating_no_out.loc[df_rating_no_out[c] > fence_high,c] = df_rating_no_out[c].quantile(0.25)
    df_rating_no_out.loc[df_rating_no_out[c] < fence_low,c] = df_rating_no_out[c].quantile(0.75)

import seaborn as sns
figure, axes = plt.subplots(nrows=8, ncols=3, figsize=(20,44))

i = 0 
j = 0

for c in df_rating_no_out.columns[6:30]:
    
    sns.boxplot(x=df_rating_no_out.Rating, y=df_rating_no_out[c], palette="Set3", ax=axes[i, j])
    
    if j == 2:
        j=0
        i+=1
    else:
        j+=1

"""The below code will test a range of models. In each we will fit the model in the train data, make predictons for the test data and obtain the accuracy. In later steps we will compare the accuracy of all the models.

Logistic Regression
"""

import time
from sklearn.feature_selection import RFECV
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(
    penalty="l2",
    solver="newton-cg",
    multi_class="multinomial",
    random_state=0,
    max_iter=1000,
    C=0.1,
)


# Recursive Feature Selection with cross-validation
# rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(5), scoring="accuracy")
# rfecv.fit(X_train, y_train)

# shows the features selected with - true
# print("support", rfecv.support_)

# X = X[:, rfecv.support_]


# Print the optimal number of features
# print("Optimal number of features : %d" % rfecv.n_features_)



# training the model
start_time = time.time()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(np.concatenate((le1.inverse_transform(y_pred).reshape(len(y_pred),1), le1.inverse_transform(y_test).reshape(len(y_test),1)),1))

from sklearn.metrics import precision_score, recall_score, f1_score
precision = precision_score(y_test, y_pred, average="macro")
recall = recall_score(y_test, y_pred, average="macro")
f1 = f1_score(y_test, y_pred, average="macro")

# print the precision, recall, and F1-score
print("Precision:", precision * 100)
print("Recall:", recall * 100)
print("F1-score:", f1 * 100)

from sklearn.metrics import accuracy_score
Accuracy_LR=accuracy_score(y_test, y_pred)
print("Accuracy score for Logistic Regression: ",Accuracy_LR)

end_time = time.time()
execution_time = end_time - start_time

print()
EsTime_LR= execution_time
print(f"Execution time: {execution_time:.6f} seconds")
#print(f"Time complexity: {X.shape[0] * X.shape[1] * np.log(model.n_neighbors):.6f}")

"""K-Nearest Neighbour """

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
start_time = time.time()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
print(np.concatenate((le1.inverse_transform(y_pred).reshape(len(y_pred),1), le1.inverse_transform(y_test).reshape(len(y_test),1)),1))

from sklearn.metrics import precision_score, recall_score, f1_score
precision = precision_score(y_test, y_pred, average="macro")
recall = recall_score(y_test, y_pred, average="macro")
f1 = f1_score(y_test, y_pred, average="macro")

# print the precision, recall, and F1-score
print("Precision:", precision * 100)
print("Recall:", recall * 100)
print("F1-score:", f1 * 100)

from sklearn.metrics import accuracy_score
Accuracy_KNN=accuracy_score(y_test, y_pred)
print("Accuracy score for K-NN: ",Accuracy_KNN)

end_time = time.time()
execution_time = end_time - start_time

print()
EsTime_KNN= execution_time
print(f"Execution time: {execution_time:.6f} seconds")
#print(f"Time complexity: {X.shape[0] * X.shape[1] * np.log(model.n_neighbors):.6f}")

"""Decision Tree Classification"""

from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
start_time = time.time()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
print(np.concatenate((le1.inverse_transform(y_pred).reshape(len(y_pred),1), le1.inverse_transform(y_test).reshape(len(y_test),1)),1))

from sklearn.metrics import precision_score, recall_score, f1_score
precision = precision_score(y_test, y_pred, average="macro")
recall = recall_score(y_test, y_pred, average="macro")
f1 = f1_score(y_test, y_pred, average="macro")

# print the precision, recall, and F1-score
print("Precision:", precision * 100)
print("Recall:", recall * 100)
print("F1-score:", f1 * 100)

from sklearn.metrics import accuracy_score
Accuracy_DT=accuracy_score(y_test, y_pred)
print("Accuracy score for Decision tree: ",Accuracy_DT)

end_time = time.time()
execution_time = end_time - start_time

print()
EsTime_DT=execution_time
print(f"Execution time: {execution_time:.6f} seconds")
#print(f"Time complexity: {X.shape[0] * X.shape[1] * np.log(model.n_neighbors):.6f}")

"""Support Vector Machine"""

from sklearn.svm import SVC
classifier = SVC(kernel = 'linear', random_state = 0)
start_time = time.time()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
print(np.concatenate((le1.inverse_transform(y_pred).reshape(len(y_pred),1), le1.inverse_transform(y_test).reshape(len(y_test),1)),1))

from sklearn.metrics import precision_score, recall_score, f1_score
precision = precision_score(y_test, y_pred, average="macro")
recall = recall_score(y_test, y_pred, average="macro")
f1 = f1_score(y_test, y_pred, average="macro")

# print the precision, recall, and F1-score
print("Precision:", precision * 100)
print("Recall:", recall * 100)
print("F1-score:", f1 * 100)

from sklearn.metrics import accuracy_score
Accuracy_SVM=accuracy_score(y_test, y_pred)
print("Accuracy score for SVM: ",Accuracy_SVM)

end_time = time.time()
execution_time = end_time - start_time

print()
EsTime_SVM= execution_time
print(f"Execution time: {execution_time:.6f} seconds")
#print(f"Time complexity: {X.shape[0] * X.shape[1] * np.log(model.n_neighbors):.6f}")

"""Kernel Support Vector Machine """

from sklearn.svm import SVC
classifier = SVC(kernel = 'rbf', random_state = 0)
start_time = time.time()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
print(np.concatenate((le1.inverse_transform(y_pred).reshape(len(y_pred),1), le1.inverse_transform(y_test).reshape(len(y_test),1)),1))

from sklearn.metrics import precision_score, recall_score, f1_score
precision = precision_score(y_test, y_pred, average="macro")
recall = recall_score(y_test, y_pred, average="macro")
f1 = f1_score(y_test, y_pred, average="macro")

# print the precision, recall, and F1-score
print("Precision:", precision * 100)
print("Recall:", recall * 100)
print("F1-score:", f1 * 100)

from sklearn.metrics import accuracy_score
Accuracy_KSV=accuracy_score(y_test, y_pred)
print("Accuracy score for Kernel SVM: ",Accuracy_KSV)

end_time = time.time()
execution_time = end_time - start_time

print()
EsTime_KSV= execution_time
print(f"Execution time: {execution_time:.6f} seconds")
#print(f"Time complexity: {X.shape[0] * X.shape[1] * np.log(model.n_neighbors):.6f}")

"""Random Forest Classification"""

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 1234)
start_time = time.time()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
print(np.concatenate((le1.inverse_transform(y_pred).reshape(len(y_pred),1), le1.inverse_transform(y_test).reshape(len(y_test),1)),1))

from sklearn.metrics import precision_score, recall_score, f1_score
precision = precision_score(y_test, y_pred, average="macro")
recall = recall_score(y_test, y_pred, average="macro")
f1 = f1_score(y_test, y_pred, average="macro")

# print the precision, recall, and F1-score
print("Precision:", precision * 100)
print("Recall:", recall * 100)
print("F1-score:", f1 * 100)

from sklearn.metrics import accuracy_score
Accuracy_RF=accuracy_score(y_test, y_pred)
print("Accuracy score for Random Forest Classification: ",Accuracy_RF)

end_time = time.time()
execution_time = end_time - start_time

print()
EsTime_RF= execution_time
print(f"Execution time: {execution_time:.6f} seconds")
#print(f"Time complexity: {X.shape[0] * X.shape[1] * np.log(model.n_neighbors):.6f}")

"""XG Boost Classification"""

#Splitting the data into training and testing data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

#Transforming the data
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from xgboost import XGBClassifier
classifier = XGBClassifier()
start_time = time.time()
classifier.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = classifier.predict(X_test)
print(np.concatenate((le1.inverse_transform(y_pred).reshape(len(y_pred),1), le1.inverse_transform(y_test).reshape(len(y_test),1)),1))
# cm = confusion_matrix(y_test, y_pred)
# print(cm)

from sklearn.metrics import precision_score, recall_score, f1_score
precision = precision_score(y_test, y_pred, average="macro")
recall = recall_score(y_test, y_pred, average="macro")
f1 = f1_score(y_test, y_pred, average="macro")

# print the precision, recall, and F1-score
print("Precision:", precision * 100)
print("Recall:", recall * 100)
print("F1-score:", f1 * 100)

from sklearn.metrics import accuracy_score
Accuracy_XGB=accuracy_score(y_test, y_pred)
print("Accuracy score for XG Boost Classification: ",Accuracy_XGB)

end_time = time.time()
execution_time = end_time - start_time

print()
EsTime_XGB= execution_time
print(f"Execution time: {execution_time:.6f} seconds")
#print(f"Time complexity: {X.shape[0] * X.shape[1] * np.log(model.n_neighbors):.6f}")

"""Comparing Results"""

accuracy_list = [Accuracy_LR, Accuracy_KNN, Accuracy_DT, Accuracy_SVM, Accuracy_KSV, Accuracy_RF, 
                 Accuracy_XGB]

model_list = ['Logistic Regression', 'K-Nearest neighbour', 'Decision Tree', 'Support Vector Machine', 
              "Kernel Support Vector Machine", 'Random Forest', 'XG Boost']

df_accuracy = pd.DataFrame({'Model': model_list, 'Accuracy': accuracy_list})

import seaborn as sns
import matplotlib.ticker as mtick
order = list(df_accuracy.sort_values('Accuracy', ascending=False).Model)
df_accuracy = df_accuracy.sort_values('Accuracy', ascending=False).reset_index().drop(['index'], axis=1)

plt.figure(figsize=(10,10))
# make barplot and sort bars
x = sns.barplot(x='Model', y="Accuracy", data=df_accuracy, order = order, palette="mako")
plt.xlabel("Model", fontsize=20)
plt.ylabel("Accuracy", fontsize=20)
plt.title("Accuracy by Model", fontsize=20)
plt.grid(linestyle='-', linewidth='0.5', color='grey')
plt.xticks(rotation=70, fontsize=12)
plt.ylim(0,1)
plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1))

for i in range(len(model_list)):
    plt.text(x = i, y = df_accuracy.loc[i, 'Accuracy'] + 0.05, s = str(round((df_accuracy.loc[i, 'Accuracy'])*100, 2))+'%', 
             fontsize = 14, color='black',horizontalalignment='center')
ax=axes[0,1]
y_value=['{:,.2f}'.format(x) + '%' for x in ax.get_yticks()]
ax.set_yticklabels(y_value)

plt.tight_layout()

Est_time_list = [EsTime_LR, EsTime_KNN, EsTime_DT, EsTime_SVM, EsTime_KSV, EsTime_RF, 
                 EsTime_XGB]

model_list = ['Logistic Regression', 'K-Nearest neighbour', 'Decision Tree', 'Support Vector Machine', 
              "Kernel Support Vector Machine", 'Random Forest', 'XG Boost']

df_EsTime = pd.DataFrame({'Model': model_list, 'Estimation Time': Est_time_list})

import seaborn as sns
import matplotlib.ticker as mtick
order = list(df_EsTime.sort_values('Estimation Time', ascending=False).Model)
df_EsTime = df_EsTime.sort_values('Estimation Time', ascending=False).reset_index().drop(['index'], axis=1)

plt.figure(figsize=(10,10))
# make barplot and sort bars
x = sns.barplot(x='Model', y="Estimation Time", data=df_EsTime, order = order, palette="magma")
plt.xlabel("Model", fontsize=20)
plt.ylabel("Estimation Time", fontsize=20)
plt.title("Estimation time for Model", fontsize=20)
plt.grid(linestyle='-', linewidth='0.5', color='grey')
plt.xticks(rotation=70, fontsize=12)
plt.ylim(0,7)
# plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1))

for i in range(len(model_list)):
    plt.text(x = i, y = df_EsTime.loc[i, 'Estimation Time'] , s = str(round((df_EsTime.loc[i, 'Estimation Time']), 2))+'s', 
             fontsize = 14, color='black',horizontalalignment='center')
ax=axes[0,1]
y_value=['{:,.2f}'.format(x) + 's' for x in ax.get_yticks()]
ax.set_yticklabels(y_value)

plt.tight_layout()